#!/usr/bin/env python3
"""
Test Script for LangGraph Conversational Agent

Tests the complete agent workflow with all 3 memory layers.
"""
import asyncio
import sys
import os
import uuid

# Add backend to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

from sqlalchemy.orm import Session
from api.db.session import SessionLocal
from api.services.agent import ConversationalAgent
from api.db.models import User, Article
import structlog

logger = structlog.get_logger()


async def test_agent():
    """Test the conversational agent end-to-end"""

    print("=" * 80)
    print("TESTING LANGGRAPH CONVERSATIONAL AGENT")
    print("=" * 80)

    db: Session = SessionLocal()

    try:
        # 1. Get or create test user
        print("\n[1] Setting up test user...")
        test_user = db.query(User).filter(User.email == "test@example.com").first()

        if not test_user:
            print("   ‚ùå No test user found. Please create one first:")
            print("   curl -X POST http://localhost:8000/api/v1/auth/signup \\")
            print("     -H 'Content-Type: application/json' \\")
            print("     -d '{\"email\":\"test@example.com\",\"password\":\"SecurePass123!\",\"full_name\":\"Test User\"}'")
            return

        print(f"   ‚úÖ Found test user: {test_user.email} (ID: {test_user.id})")

        # 2. Check if we have articles
        print("\n[2] Checking available articles...")
        article_count = db.query(Article).count()
        print(f"   üìä Found {article_count} articles in database")

        if article_count == 0:
            print("   ‚ö†Ô∏è  No articles found - agent will have limited context")

        # 3. Initialize agent
        print("\n[3] Initializing conversational agent...")
        print("   üîß Using Groq LLM (llama-3.3-70b-versatile)")

        test_session_id = str(uuid.uuid4())  # Generate proper UUID for session

        agent = ConversationalAgent(
            user_id=str(test_user.id),
            session_id=test_session_id,
            db=db,
            use_groq=True  # Use Groq for better responses
        )

        print("   ‚úÖ Agent initialized successfully")
        print(f"   üìä Memory layers: Digest Context, Short-Term, Long-Term")

        # 4. Get agent stats
        print("\n[4] Agent statistics:")
        stats = agent.get_stats()
        print(f"   User ID: {stats['user_id']}")
        print(f"   Session ID: {stats['session_id']}")
        print(f"   LLM: {stats['llm_type']}")
        print(f"   Memory Stats:")
        for layer, layer_stats in stats['memory_stats'].items():
            print(f"      {layer}: {layer_stats}")

        # 5. Test queries
        print("\n[5] Testing agent with different query types...")

        test_queries = [
            ("greeting", "Hello! What can you help me with?"),
            ("today_question", "What are the latest articles I have?"),
            ("question", "What articles do I have about AI?"),
            ("general", "Thanks for the help!"),
        ]

        for query_type, query in test_queries:
            print(f"\n   üìù Query Type: {query_type}")
            print(f"   üí¨ User: {query}")
            print("   ü§ñ Processing...")

            try:
                response = await agent.chat(query)

                print(f"   ‚úÖ Response received!")
                print(f"   üì§ Assistant: {response['response'][:200]}...")
                print(f"   üß† Memory layers used: {response['memory_layers_used']}")
                print(f"   üéØ Query type detected: {response['query_type']}")
                print(f"   üìä Confidence: {response['confidence']:.2f}")

                if response['sources']:
                    print(f"   üìö Sources: {len(response['sources'])} articles")
                    for i, source in enumerate(response['sources'][:2], 1):
                        print(f"      {i}. {source['title']} (Relevance: {source['relevance_score']:.0%})")

            except Exception as e:
                print(f"   ‚ùå Error: {str(e)}")
                import traceback
                traceback.print_exc()

        # 6. Test conversation history
        print("\n[6] Testing conversation history...")
        history = agent.short_term_memory.get_messages()
        print(f"   üìä Total messages in session: {len(history)}")
        print(f"   üí¨ Conversation turns: {len(history) // 2}")

        if history:
            print(f"   üìù Last 2 messages:")
            for msg in history[-2:]:
                role_icon = "üë§" if msg["role"] == "user" else "ü§ñ"
                print(f"      {role_icon} {msg['role']}: {msg['content'][:100]}...")

        # 7. Test digest context
        print("\n[7] Testing digest context memory (Layer 1)...")
        context_summary = agent.digest_memory.get_context_summary()
        print(f"   üìä Context summary length: {len(context_summary)} chars")
        print(f"   üìù Summary preview:")
        for line in context_summary.split('\n')[:5]:
            print(f"      {line}")

        # 8. Test long-term memory
        print("\n[8] Testing long-term memory (Layer 3)...")
        if article_count > 0:
            try:
                results = await agent.long_term_memory.search(
                    query="artificial intelligence",
                    top_k=3
                )
                print(f"   ‚úÖ Semantic search works!")
                print(f"   üìö Found {len(results)} relevant articles")
                for i, article in enumerate(results, 1):
                    print(f"      {i}. {article['title']} (Relevance: {article['relevance_score']:.0%})")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Semantic search error: {str(e)}")
        else:
            print("   ‚è≠Ô∏è  Skipped (no articles)")

        print("\n" + "=" * 80)
        print("‚úÖ AGENT TESTING COMPLETE")
        print("=" * 80)

        print("\nüìä Summary:")
        print(f"   ‚Ä¢ Agent initialized: ‚úÖ")
        print(f"   ‚Ä¢ Memory layers: ‚úÖ (3/3 working)")
        print(f"   ‚Ä¢ Query processing: ‚úÖ")
        print(f"   ‚Ä¢ LLM integration: ‚úÖ")
        print(f"   ‚Ä¢ Conversation history: ‚úÖ")

    except Exception as e:
        print(f"\n‚ùå FATAL ERROR: {str(e)}")
        import traceback
        traceback.print_exc()

    finally:
        db.close()


if __name__ == "__main__":
    asyncio.run(test_agent())
